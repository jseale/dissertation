{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "**Functionality**: Confirm lack of variance in certain WHD homograph data classes\n",
    "\n",
    "**Use**: Use results to create only variant dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths \n",
    "WHD_DATA = \"C:/Users/jseal/Dev/dissertation/Data/WikipediaHomographData/data/\"\n",
    "TRAIN = WHD_DATA + \"train/\"\n",
    "EVAL = WHD_DATA + \"eval/\"\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# THREE_SPLITS = WHD_DATA + \"three_split_data/\"\n",
    "# NEW_TRAIN = THREE_SPLITS + \"train/\"\n",
    "# NEW_DEV = THREE_SPLITS + \"dev/\"\n",
    "# NEW_TEST = THREE_SPLITS + \"test/\"\n",
    "\n",
    "# #Variables\n",
    "# RANDOM_STATE = 45\n",
    "# FRAC = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 162/162 [00:00<00:00, 774.99it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for f in tqdm(glob(TRAIN +'*.tsv')):\n",
    "    df = pd.read_table(f)\n",
    "    dfs.append(df)\n",
    "\n",
    "train_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>homograph</th>\n",
       "      <th>wordid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract_adj-nou</td>\n",
       "      <td>Smith uses his name as a base for building abs...</td>\n",
       "      <td>43</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract_adj-nou</td>\n",
       "      <td>The Group intended to promote Welsh radical an...</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract_adj-nou</td>\n",
       "      <td>Both stances are verbalized with the same abst...</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract_adj-nou</td>\n",
       "      <td>In later years he became less prolific, and un...</td>\n",
       "      <td>96</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abstract</td>\n",
       "      <td>abstract_adj-nou</td>\n",
       "      <td>As a sculptor, Ruud Kuijer became famous for h...</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  homograph            wordid  \\\n",
       "0  abstract  abstract_adj-nou   \n",
       "1  abstract  abstract_adj-nou   \n",
       "2  abstract  abstract_adj-nou   \n",
       "3  abstract  abstract_adj-nou   \n",
       "4  abstract  abstract_adj-nou   \n",
       "\n",
       "                                            sentence  start  end  \n",
       "0  Smith uses his name as a base for building abs...     43   51  \n",
       "1  The Group intended to promote Welsh radical an...     48   56  \n",
       "2  Both stances are verbalized with the same abst...     42   50  \n",
       "3  In later years he became less prolific, and un...     96  104  \n",
       "4  As a sculptor, Ruud Kuijer became famous for h...     49   57  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "homograph\n",
       "pigment         1\n",
       "moped           1\n",
       "elaborate       1\n",
       "entrance        1\n",
       "mouth           1\n",
       "row             1\n",
       "desert          1\n",
       "conglomerate    1\n",
       "job             1\n",
       "subject         1\n",
       "object          1\n",
       "intimate        1\n",
       "interchange     1\n",
       "instrument      1\n",
       "addict          1\n",
       "incense         1\n",
       "consort         1\n",
       "compact         1\n",
       "ornament        2\n",
       "mobile          2\n",
       "nestle          2\n",
       "overthrow       2\n",
       "pasty           2\n",
       "perfect         2\n",
       "perfume         2\n",
       "moderate        2\n",
       "abstract        2\n",
       "minute          2\n",
       "initiate        2\n",
       "insert          2\n",
       "insult          2\n",
       "intrigue        2\n",
       "invalid         2\n",
       "invert          2\n",
       "invite          2\n",
       "isolate         2\n",
       "jesus           2\n",
       "laminate        2\n",
       "lead            2\n",
       "learned         2\n",
       "permit          2\n",
       "lives           2\n",
       "mate            2\n",
       "misuse          2\n",
       "live            2\n",
       "precipitate     2\n",
       "polish          2\n",
       "sake            2\n",
       "separate        2\n",
       "sow             2\n",
       "subordinate     2\n",
       "supplement      2\n",
       "suspect         2\n",
       "syndicate       2\n",
       "tear            2\n",
       "transform       2\n",
       "transplant      2\n",
       "transport       2\n",
       "upset           2\n",
       "use             2\n",
       "uses            2\n",
       "wind            2\n",
       "rodeo           2\n",
       "retard          2\n",
       "resume          2\n",
       "rerelease       2\n",
       "postulate       2\n",
       "predicate       2\n",
       "present         2\n",
       "produce         2\n",
       "progress        2\n",
       "project         2\n",
       "protest         2\n",
       "pervert         2\n",
       "ravel           2\n",
       "reading         2\n",
       "rebel           2\n",
       "record          2\n",
       "recount         2\n",
       "refund          2\n",
       "refuse          2\n",
       "reject          2\n",
       "read            2\n",
       "increment       2\n",
       "implement       2\n",
       "incline         2\n",
       "bow             2\n",
       "buffet          2\n",
       "celtic          2\n",
       "close           2\n",
       "combine         2\n",
       "compound        2\n",
       "compress        2\n",
       "conduct         2\n",
       "confines        2\n",
       "conflict        2\n",
       "conjugate       2\n",
       "conscript       2\n",
       "console         2\n",
       "construct       2\n",
       "consummate      2\n",
       "bologna         2\n",
       "content         2\n",
       "blessed         2\n",
       "axes            2\n",
       "abuse           2\n",
       "abuses          2\n",
       "advocate        2\n",
       "affect          2\n",
       "affiliate       2\n",
       "aged            2\n",
       "aggregate       2\n",
       "alternate       2\n",
       "analyses        2\n",
       "animate         2\n",
       "appropriate     2\n",
       "approximate     2\n",
       "articulate      2\n",
       "associate       2\n",
       "attribute       2\n",
       "bass            2\n",
       "increase        2\n",
       "contest         2\n",
       "contrast        2\n",
       "estimate        2\n",
       "excuse          2\n",
       "expatriate      2\n",
       "exploit         2\n",
       "export          2\n",
       "expose          2\n",
       "extract         2\n",
       "fragment        2\n",
       "frequent        2\n",
       "graduate        2\n",
       "house           2\n",
       "impact          2\n",
       "implant         2\n",
       "winds           2\n",
       "import          2\n",
       "escort          2\n",
       "contract        2\n",
       "duplicate       2\n",
       "document        2\n",
       "converse        2\n",
       "convert         2\n",
       "convict         2\n",
       "coordinate      2\n",
       "correlate       2\n",
       "decrease        2\n",
       "defect          2\n",
       "degenerate      2\n",
       "delegate        2\n",
       "deliberate      2\n",
       "deviate         2\n",
       "diagnoses       2\n",
       "diffuse         2\n",
       "discard         2\n",
       "discharge       2\n",
       "discount        2\n",
       "dove            2\n",
       "wound           2\n",
       "august          3\n",
       "Name: wordid, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('homograph')['wordid'].nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation_huggingface",
   "language": "python",
   "name": "dissertation_huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
