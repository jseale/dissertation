{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import List\n",
    "from glob import iglob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUT = '/Users/jen/Dev/Dissertation/dissertation/Data/SWBD/MFA_SPLIT/'\n",
    "PATH_WAV = '/Users/jen/Dev/Dissertation/dissertation/Data/SWBD/wavs'\n",
    "PATH_TERMS = '/Users/jen/Dev/Dissertation/dissertation/Data/SWBD/terminals'\n",
    "PATH_WHD = '/Users/jen/Dev/Dissertation/dissertation/Data/WikipediaHomographData.csv'\n",
    "#IN = os.path.join(PATH, 'sw04603.wav')\n",
    "whd_df = pd.read_csv(PATH_WHD)\n",
    "homographs = whd_df['homograph'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authored by Andrew Jiang\n",
    "# BCG digital Ventures\n",
    "import os, wave, math, collections\n",
    "\n",
    "# define named tuples\n",
    "metatuple = collections.namedtuple('metatuple', ['nchannels', 'sampwidth', 'framerate', 'nframes', 'comptype', 'compname'])\n",
    "datatuple = collections.namedtuple('datatuple', ['meta', 'data'])\n",
    "\n",
    "# opens a wav file and returns the data as a tuple\n",
    "def readwave(src):\n",
    "    read = wave.open(src, 'rb')\n",
    "    meta = read.getparams()\n",
    "    # turn params into a metatuple\n",
    "    meta = metatuple(meta[0], meta[1], meta[2], meta[3], meta[4], meta[5])\n",
    "    data = read.readframes(meta.nframes)\n",
    "    read.close()\n",
    "    return datatuple(meta, [data])\n",
    "\n",
    "# writes to a directory\n",
    "def writewave(dest, data):\n",
    "    files = []\n",
    "    data = separate(data)\n",
    "    #print('length of data')\n",
    "    #print(len(data))\n",
    "    #print(data)\n",
    "    for i in range(len(data)):\n",
    "        destfile = dest\n",
    "        makedir(destfile) # make sure dir exists\n",
    "        write = wave.open(destfile, 'wb')\n",
    "        write.setparams(data[i].meta)\n",
    "        write.writeframes(data[i].data)\n",
    "        write.close()\n",
    "        files.append(destfile)\n",
    "    return files\n",
    "\n",
    "# helper function that creates dir if it doesn't exist\n",
    "def makedir(dest):\n",
    "    if(os.path.isdir(os.path.dirname(dest)) != True):\n",
    "        os.makedirs(os.path.dirname(dest))\n",
    "\n",
    "# slices audio data at given start, end: frame#\n",
    "def slicewave(data, start, end):\n",
    "    if(len(data.data) > 1):\n",
    "        data = merge(data) # insurance\n",
    "    meta = data.meta\n",
    "    start *= meta.sampwidth # deal with sample width\n",
    "    end *= meta.sampwidth\n",
    "    spliced = data.data[0][start:end]\n",
    "    nf = len(spliced) / meta.sampwidth\n",
    "    meta = meta._replace(nframes=nf)\n",
    "    return datatuple(meta, [spliced])\n",
    "\n",
    "# slices audio data at given start, end: seconds\n",
    "def slicewave_s(data, start, end):\n",
    "    fr = float(data.meta.framerate)\n",
    "    newdata = slicewave(data, int(float(start) * fr), int(float(end) * fr))\n",
    "    return newdata\n",
    "\n",
    "# splits audio data into equal intervals: # of frames\n",
    "def split(data, interval=None, overlap=None):\n",
    "    if(interval == None):\n",
    "        interval = data.meta.framerate # =1s\n",
    "    if(overlap == None):\n",
    "        overlap = interval\n",
    "    if(interval < 1 or overlap < 1):\n",
    "        raise ValueError('cannot iterate')\n",
    "    iterations = int(math.ceil(1.0 * data.meta.nframes / interval))\n",
    "    canned = []\n",
    "    for i in range(iterations):\n",
    "        start = i * interval\n",
    "        end = start + overlap\n",
    "        canned.append(slicewave(data, start, end))\n",
    "    newdata = combine(canned)\n",
    "    return newdata\n",
    "\n",
    "# splits audio data into equal intervals: seconds\n",
    "def split_s(data, interval=None, overlap=None):\n",
    "    fr = float(data.meta.framerate)\n",
    "    if(interval != None):\n",
    "        interval = int(float(interval) * fr)\n",
    "    if(overlap != None):\n",
    "        overlap = int(float(overlap) * fr)\n",
    "    newdata = split(data, interval, overlap)\n",
    "    return newdata\n",
    "\n",
    "# separate a data tuple containing multiple audio tracks\n",
    "# into an array of data tuples containing single audio tracks\n",
    "def separate(data):\n",
    "    newdata = []\n",
    "    nframes = data.meta.nframes\n",
    "    ndata = len(data.data)\n",
    "    for i in range(ndata):\n",
    "        nf = len(data.data[i]) / data.meta.sampwidth\n",
    "        meta = data.meta._replace(nframes=nf)\n",
    "        newdata.append(datatuple(meta, data.data[i]))\n",
    "    return newdata\n",
    "\n",
    "# combine an array of data tuples containing single audio tracks\n",
    "# into a single data tuple containing multiple audio tracks\n",
    "def combine(data):\n",
    "    newdata = []\n",
    "    meta = data[0].meta\n",
    "    for i in range(len(data)):\n",
    "        newdata += data[i].data\n",
    "    nf = len(''.join(newdata)) / meta.sampwidth\n",
    "    meta = meta._replace(nframes=nf)\n",
    "    return datatuple(meta, newdata)\n",
    "\n",
    "# merge multiple audio tracks into one\n",
    "def merge(data):\n",
    "    meta = data.meta\n",
    "    newdata = ''.join(data.data)\n",
    "    return datatuple(meta, [newdata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "# data = readwave(IN)\n",
    "# A1 = slicewave_s(data, 1.7*2, 24.4*2)\n",
    "# A2 = slicewave_s(data, 25.6*2, 50.3*2)\n",
    "# writewave(OUT, A1)\n",
    "# writewave(OUT_1, A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = \"{http://nite.sourceforge.net/}start\"\n",
    "END = \"{http://nite.sourceforge.net/}end\"\n",
    "ID = \"{http://nite.sourceforge.net/}id\"\n",
    "PW = 'phonword'\n",
    "ORTH = 'orth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orths(FILE : str, item_type : str, start_time: float, end_time: float) -> List: \n",
    "    orths = []\n",
    "    tree = ET.parse(FILE)\n",
    "    root = tree.getroot()\n",
    "    for item in root.findall(item_type): \n",
    "        start = float(item.get(START))\n",
    "        end = float(item.get(END))\n",
    "        if start >= start_time and end <= math.ceil(end_time): \n",
    "            orths.append(item.get(ORTH))\n",
    "    return orths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IDS(terminals: str):\n",
    "    IDS = []\n",
    "    term_tree = ET.parse(terminals)\n",
    "    for e in term_tree.iter(): \n",
    "        if e.get(ID) != None:\n",
    "            IDS.append(e.get(ID))\n",
    "    return IDS\n",
    "\n",
    "def get_unique_prefixes(IDS): \n",
    "    prefixes = []\n",
    "    for e in IDS:\n",
    "        if e.find('-') == -1: \n",
    "            prefixes.append(e.split('_')[0])\n",
    "    return set(prefixes)\n",
    "    \n",
    "def get_sentence_ids(uniques, IDS):\n",
    "    sentences = []\n",
    "    for u in uniques: \n",
    "        sentence_dict = {}\n",
    "        sentence_ids = []\n",
    "        for i in IDS: \n",
    "            if i.startswith(u+\"_\"): \n",
    "                sentence_ids.append(i)\n",
    "        sentence_dict['unique'] = u\n",
    "        sentence_dict['seq'] = sentence_ids\n",
    "        sentence_dict['start_id'] = sentence_ids[0]\n",
    "        sentence_dict['end_id'] = sentence_ids[-1]\n",
    "        sentences.append(sentence_dict)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def go_fwd(ID):\n",
    "    prefix, endfix = ID.split('_')\n",
    "    endfix_int = int(endfix)\n",
    "    endfix_fwd = endfix_int + 1\n",
    "    endfix_fwd_str = str(endfix_fwd)\n",
    "    return prefix + \"_\" + endfix_fwd_str\n",
    "\n",
    "def recurs_fwd(sentence_start_id, sentence, root):\n",
    "    next_ = go_fwd(sentence_start_id)\n",
    "    for e in root.iter(): \n",
    "        if e.get(ID) == next_:\n",
    "            start = e.get(START)\n",
    "            if (start != None) & (start != 'n/a'): \n",
    "                sentence['start_id'] = next_\n",
    "                sentence['start'] = start\n",
    "            else:\n",
    "                next_, sentence, root = recurs_fwd(next_, sentence, root)\n",
    "    return next_, sentence, root\n",
    "\n",
    "def go_back(ID):\n",
    "    prefix, endfix = ID.split('_')\n",
    "    endfix_int = int(endfix)\n",
    "    endfix_back = endfix_int - 1\n",
    "    endfix_back_str = str(endfix_back)\n",
    "    return prefix + \"_\" + endfix_back_str\n",
    "\n",
    "def recurs_back(sentence_end_id, sentence, root):\n",
    "    previous = go_back(sentence_end_id)\n",
    "    for e in root.iter(): \n",
    "        if e.get(ID) == previous:\n",
    "            end = e.get(END)\n",
    "            if end != None: \n",
    "                sentence['end_id'] = previous\n",
    "                sentence['end'] = end\n",
    "            else:\n",
    "                previous, sentence, root = recurs_back(previous, sentence, root)\n",
    "    return previous, sentence, root\n",
    "\n",
    "def get_start_end(setence_ids, terminals): \n",
    "    tree = ET.parse(terminals)\n",
    "    root = tree.getroot()\n",
    "    for sentence in sentence_ids:\n",
    "        orths = []\n",
    "        for e in root.iter():\n",
    "            _id = e.get(ID)\n",
    "            if _id in sentence['seq']: \n",
    "                if e.get(ORTH) != None: \n",
    "                    orths.append(e.get(ORTH))\n",
    "            if _id == sentence['start_id']:\n",
    "                start = e.get(START)\n",
    "                if start != None:\n",
    "                    sentence['start'] = start\n",
    "                elif (start == None) or (start == 'n/a'): \n",
    "                    start, sentence, root = recurs_fwd(sentence['start_id'], sentence, root)\n",
    "                    \n",
    "            elif _id == sentence['end_id']: \n",
    "                end = e.get(END)\n",
    "                if end != None:\n",
    "                    sentence['end'] = end\n",
    "                if end == None: \n",
    "                    #Look back for the end of the sentence\n",
    "                    previous, sentence, root = recurs_back(sentence['end_id'], sentence, root)\n",
    "\n",
    "            sentence['sentence'] = orths\n",
    "    return sentence_ids    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test\n",
    "# terminals = os.path.join(PATH,\"sw4603.A.terminals.xml\")\n",
    "# IDS = get_IDS(terminals)\n",
    "# uniques = get_unique_prefixes(IDS)\n",
    "# sentence_ids = get_sentence_ids(uniques, IDS)    \n",
    "# sentence_data = get_start_end(sentence_ids, terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in sentence_data: \n",
    "#     for orth in e['sentence']:\n",
    "#         if orth in homographs: #filter out non-homograph data\n",
    "#             #Create lab file\n",
    "#             with open('{}/A1/sw04603_{}.lab'.format(PATH, e['start_id'] + \"-\" + e['end_id']), 'w') as f: \n",
    "#                 f.write(' '.join(e['sentence']))\n",
    "#             #Create wav file\n",
    "#             data = readwave('{}/sw04603.wav'.format(PATH))\n",
    "#             start_time = float(\"{:.1f}\".format(float(e['start'])))*2\n",
    "#             end_time = float(\"{:.1f}\".format(float(e['end'])))*2\n",
    "#             content = slicewave_s(data,  start_time, end_time)\n",
    "#             OUT = '{}/A1/sw04603_{}.wav'.format(PATH, e['start_id'] + \"-\" + e['end_id'])\n",
    "#             writewave(OUT, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All\n",
    "for term in iglob(os.path.join(PATH_TERMS, '*')): \n",
    "    # get corresponding lab, wav file names\n",
    "    file_name = os.path.basename(term)[:6]\n",
    "    basename = file_name[:2] + \"0\" + file_name[2:]\n",
    "    wav = file_name[:2] + \"0\" + file_name[2:] + \".wav\"\n",
    "    # get the sentence\n",
    "    IDS = get_IDS(term)\n",
    "    uniques = get_unique_prefixes(IDS)\n",
    "    sentence_ids = get_sentence_ids(uniques, IDS)    \n",
    "    sentence_data = get_start_end(sentence_ids, term)\n",
    "    for e in sentence_data: \n",
    "        for orth in e['sentence']:\n",
    "            if orth in homographs: #filter out non-homograph data\n",
    "                #Create lab file\n",
    "                with open('{}{}_{}.lab'.format(PATH_OUT, basename, e['start_id'] + \"-\" + e['end_id']), 'w') as f: \n",
    "                    f.write(' '.join(e['sentence']))\n",
    "                #Create wav file\n",
    "                try:\n",
    "                    data = readwave('{}/{}'.format(PATH_WAV, wav))\n",
    "                    start_time = float(\"{:.1f}\".format(float(e['start'])))*2\n",
    "                    end_time = float(\"{:.1f}\".format(float(e['end'])))*2\n",
    "                    content = slicewave_s(data,  start_time, end_time)\n",
    "                    OUT = '{}{}_{}.wav'.format(PATH_OUT, basename, e['start_id'] + \"-\" + e['end_id'])\n",
    "                    writewave(OUT, content)\n",
    "                except: \n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation",
   "language": "python",
   "name": "dissertation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
